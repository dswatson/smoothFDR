% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/smoothFDR.R
\name{smoothFDR}
\alias{smoothFDR}
\title{FDR Smoothing}
\usage{
smoothFDR(
  dat,
  probe = "probe",
  z = "z",
  pos = "pos",
  chr = "chr",
  nulltype = "empirical",
  nlambda = 30,
  tol = 1e-06,
  maxit = 100,
  parallel = TRUE
)
}
\arguments{
\item{dat}{Data frame with columns for probe name, z-statistics, chromosomal 
position, and chromosome.}

\item{probe}{String denoting column name for probes (CpGs, SNPs, etc.).}

\item{z}{String denoting column name for z-scores.}

\item{pos}{String denoting column name for chromosomal positions.}

\item{chr}{String denoting column name for chromosomes.}

\item{nulltype}{How should the null distribution be estimated? Choose 
\code{"empirical"} for Efron's central-matching method (default). Choose
\code{"theoretical"} for a standard normal null.}

\item{nlambda}{Length of the lambda sequence for the fused lasso subroutine.}

\item{tol}{Convergence tolerance for the expectation maximization (EM) 
algorithm.}

\item{maxit}{Maximum number of iterations for the EM algorithm.}

\item{parallel}{Process in parallel? Only relevant if data spans multiple 
chromosomes. If \code{TRUE}, backend must be registered beforehand.}
}
\description{
This function implements Tansey et al.'s (2018) FDR smoothing algorithm.
}
\details{
FDR smoothing is an empirical Bayes method for exploiting spatial structure 
in large multiple-testing problems. The method automatically finds 
spatially localized regions of significant test statistics. It then relaxes 
the threshold of statistical significance within these regions and tightens 
it elsewhere, in a manner that controls the overall false discovery rate at a 
given level. This results in increased power and cleaner spatial separation 
of signals from noise. The approach requires solving a nonstandard 
high-dimensional optimization problem, for which an efficient 
augmented-Lagrangian algorithm is implemented. See (Tansey et al., 2018) 
for details.
}
\examples{
# Import data
data('DNAm_chr1')

# Set seed
set.seed(123)

# Run FDR smoothing
res <- smoothFDR(DNAm_chr1)

# Compare q-values to Benjamini-Hochberg estimates
sum(res$BH <= 0.05)
sum(res$q.value <= 0.05)

}
\references{
Efron, B. (2004). \href{https://bit.ly/2kYx5AR}{Large-Scale Simultaneous 
Hypothesis Testing: The Choice of a Null Hypothesis}. \emph{JASA, 99}(465),
96-104.

Newton, M.A. (2002). \href{https://bit.ly/2kYjCce}{On a Nonparametric 
Recursive Estimator of the Mixing Distribution}. \emph{SankhyÄ: The Indian
Journal of Statistics, Series A, 64}(2), 306-322. 

Tansey, W., Koyejo, O., Poldrack, R.A., & Scott, J.G. (2018). 
\href{https://bit.ly/2msEdWH}{False Discovery Rate Smoothing}. \emph{JASA, 
113}(523), 1156-1171.

Tibshirani, R., Saunders, M., Rosset, S., Zhu, J., & Knight, K. (2005). 
\href{https://stanford.io/2lYzEmJ}{Sparsity and Smoothness via the Fused
Lasso}. \emph{J. R. Statist. Soc. B, 67}(1), 91-108.
}
